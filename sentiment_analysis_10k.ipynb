{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0b80bb-8535-477c-9e8d-d8f621a387c2",
   "metadata": {},
   "source": [
    "## Installing & Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507f2d0-d3a6-4b79-b9d6-12701a2d6692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets nltk tqdm scikit-learn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a0618-1ff9-470e-aa3c-c2999e370806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from datasets import Dataset\n",
    "#from scipy.stats import pearsonr, ttest_rel\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f763cc9-193e-49ba-aa7e-f2ff1b7c1ce7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec14769-e1f8-4376-95a5-196975a38d83",
   "metadata": {},
   "source": [
    "## Downloading .idx files from SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39241d2-e76d-4b42-8724-5dcee1969be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO download the .idx files -- only run this if you dont have the idx files upfront\n",
    "# Base URL for the SEC EDGAR full index\n",
    "base_url = 'https://www.sec.gov/Archives/edgar/full-index/'\n",
    "\n",
    "# Function to download the file, now includes headers parameter\n",
    "def download_file(url, path, headers):\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "# Prompt for start and end year\n",
    "start_year = int(input(\"Enter the start year (YYYY): \"))\n",
    "end_year = int(input(\"Enter the end year (YYYY): \"))\n",
    "save_dir = input('Please Input Path to Your Directory to Download Files:')\n",
    "\n",
    "# Add your user-agent string here\n",
    "headers = {'User-Agent': 'simransukhawani3@gmail.com'}\n",
    "\n",
    "# Iterate over each year and quarter within the specified range\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for quarter in ['QTR1', 'QTR2', 'QTR3', 'QTR4']:\n",
    "        file_url = f\"{base_url}{year}/{quarter}/company.idx\"\n",
    "        save_path = os.path.join(save_dir, f\"{year}_{quarter}_company.idx\")\n",
    "\n",
    "        print(f\"Attempting to download {file_url}...\")\n",
    "\n",
    "        # Make the download attempt\n",
    "        try:\n",
    "            download_file(file_url, save_path, headers)\n",
    "            print(f\"Successfully downloaded {file_url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {file_url}. Error: {e}\")\n",
    "\n",
    "        # Respect the SEC's rate limiting\n",
    "        time.sleep(1)  # Sleep for 1 second to avoid hitting rate limit\n",
    "\n",
    "print(\"All requested files have been attempted to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba09e5-b67d-4de8-a295-8f796a5395f7",
   "metadata": {},
   "source": [
    "## Creating a dataframe using all the .idx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d824f87-7a1a-49f3-9f22-c8a52f390516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To create the dataframe for the links from the .idx files and saving it into a csv\n",
    "# Adjusting pandas display options for more optimized data viewing\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to terminal size\n",
    "pd.set_option('display.max_colwidth', None)  # Display full content of each cell\n",
    "\n",
    "#Load data from all EDGAR index files in the specified director\n",
    "def load_data_from_directory(source_dir):\n",
    "    colspecs = [(0, 62), (62, 74), (74, 86), (86, 98), (98, None)]\n",
    "    column_names = ['Company Name', 'Form Type', 'CIK', 'Date Filed', 'Filename']\n",
    "    dataframe_collection = []\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if file_name.endswith('.idx'):  # Check for .idx files\n",
    "            file_path = os.path.join(source_dir, file_name)\n",
    "            try:\n",
    "                # Read fixed-width file with specified columns and skip header rows\n",
    "                temp_df = pd.read_fwf(file_path, colspecs=colspecs, skiprows=9, names=column_names)\n",
    "                dataframe_collection.append(temp_df)\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(f'Error reading {file_name}: {e}')\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f'An unexpected error occurred while reading {file_name}: {e}')\n",
    "                continue\n",
    "\n",
    "    if not dataframe_collection:\n",
    "        print(\"No data was loaded. Please check your file paths and names.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all DataFrames into one DataFrame\n",
    "    combined_df = pd.concat(dataframe_collection, ignore_index=True)\n",
    "    combined_df.columns = combined_df.columns.str.strip()  # Strip any leading/trailing whitespace from column names\n",
    "    return combined_df\n",
    "\n",
    "def save_to_csv(df, output_path):\n",
    "    \"\"\"Save DataFrame to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Data saved successfully to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save the DataFrame: {e}\")\n",
    "\n",
    "# Main execution logic\n",
    "if __name__ == \"__main__\":\n",
    "    source_directory = input('Enter/path/to/data/directory: ')  # Get directory containing the data files from user\n",
    "    csv_name = input('Enter the filename for the CSV (e.g., combined_data.csv): ')\n",
    "    output_path = os.path.join(source_directory, csv_name)  # Construct the full path to save the CSV file\n",
    "\n",
    "    # Load data from the specified directory\n",
    "    all_data_df = load_data_from_directory(source_directory)\n",
    "\n",
    "    # Save the data to a CSV file\n",
    "    if not all_data_df.empty:\n",
    "        save_to_csv(all_data_df, output_path)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a72ac-c4e2-4fd0-b0d9-4aecbc496de1",
   "metadata": {},
   "source": [
    "# Data Modeling & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989528c0-53d9-4efb-b96d-ea84db495ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the combined_data.csv that contains the filings links of all the companies\n",
    "df_idx = pd.read_csv(\"data/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_idx.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd312470-565e-401a-9f11-6c610e7f0050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the sp500 company list\n",
    "df_sp500 = pd.read_excel(\"data/sp500_cik.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84222f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_sp500.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26dc41-c511-4820-a609-7f930fc67175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering only the Symbol and CIK columns of the data\n",
    "df_cik = df_sp500[[\"Symbol\",\"CIK\"]]\n",
    "df_cik.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6576b-74e4-4941-ac49-5f206ae55395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df_cik[\"CIK\"]))\n",
    "print(len(df_idx[\"CIK\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7f304-fb11-420a-931e-4d4b136ca070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Making sure that both the dataframe CIK columns are of same type\n",
    "df_idx['CIK']  = df_idx['CIK'].astype(str)\n",
    "df_cik['CIK']  = df_cik['CIK'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047eb11",
   "metadata": {},
   "source": [
    "### Filtering out the S&P500 companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d2f54-a41a-4cf6-bd0b-13757fa0a613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering the idx dataframe to only include rows where the CIK is in the sp500 list\n",
    "sp500_ciks = df_cik['CIK'].unique()\n",
    "filtered = df_idx[df_idx['CIK'].isin(sp500_ciks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504efa0c-2b26-4a70-8ca0-7e3f7a39d97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170d2cc-5027-4ebf-b316-25ca31b3c2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking the number of unique CIKs in the filtered dataframe\n",
    "unique_names= filtered[\"CIK\"].unique()\n",
    "print(len(unique_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d971d-51c6-48a7-86c4-623ff5ae4d6d",
   "metadata": {},
   "source": [
    "## Extracting HTML contents of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e3de4-d82d-41c6-9199-525bc7cb5c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To extract the html content from the SEC page\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def extract_filing_html_directly(row, user_agent_email):\n",
    "    \"\"\"\n",
    "    Extracts the actual 10-K filing HTML content from a row in .idx using the real HTML URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = row['Filename'].strip().replace(\" \", \"\")\n",
    "        path_parts = filename.split(\"/\")\n",
    "\n",
    "        if len(path_parts) < 4:\n",
    "            print(f\"Invalid path in Filename: {filename}\")\n",
    "            return None, None\n",
    "\n",
    "        cik = path_parts[2]\n",
    "        accession_with_dashes = path_parts[3]\n",
    "        accession_nodashes = accession_with_dashes.replace(\"-\", \"\")\n",
    "        index_filename = accession_with_dashes + \"-index.htm\"\n",
    "\n",
    "        index_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_nodashes}/{index_filename}\"\n",
    "        headers = {\"User-Agent\": user_agent_email}\n",
    "\n",
    "        response = requests.get(index_url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to load index page: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        doc_table = soup.find(\"table\", class_=\"tableFile\")\n",
    "        if doc_table is None:\n",
    "            print(f\"Could not find document table at: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        doc_link_tag = doc_table.find(\"a\", href=lambda href: href and href.endswith(\".htm\") and not href.endswith(\"-index.htm\"))\n",
    "        if doc_link_tag is None:\n",
    "            print(f\"No .htm filing document found in index page: {index_url}\")\n",
    "            return None, None\n",
    "\n",
    "        primary_doc = doc_link_tag['href'].lstrip(\"/\")  # remove leading slash\n",
    "        filing_url = f\"https://www.sec.gov/{primary_doc}\"  # FIXED — no double Archives\n",
    "\n",
    "        filing_response = requests.get(filing_url, headers=headers, timeout=15)\n",
    "        if filing_response.status_code == 200:\n",
    "            print(f\"Downloaded: {filing_url}\")\n",
    "            return filing_url, filing_response.text\n",
    "        else:\n",
    "            print(f\"Failed to download filing from: {filing_url}\")\n",
    "            return filing_url, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2de1e3-7efb-448c-b4c4-3afd9f2c5066",
   "metadata": {},
   "source": [
    "## Cleaning the HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9458d-45f6-4a83-9845-76f5012a315b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaning the HTML content of the filing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_filing_html(filing_html):\n",
    "    \"\"\"\n",
    "    Cleans the full HTML of a 10-K filing to extract readable plain text.\n",
    "    Removes scripts, styles, and unnecessary whitespace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(filing_html, \"html.parser\")\n",
    "\n",
    "        # Remove unwanted tags\n",
    "        for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"noscript\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        # Extract text from the body if present\n",
    "        body = soup.find(\"body\")\n",
    "        raw_text = body.get_text(separator=\"\\n\") if body else soup.get_text(separator=\"\\n\")\n",
    "\n",
    "        # Normalize whitespace\n",
    "        lines = [line.strip() for line in raw_text.splitlines()]\n",
    "        clean_text = \"\\n\".join(line for line in lines if line)\n",
    "\n",
    "        return clean_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error cleaning HTML: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44cb19-d0fe-4f96-91d1-c01b395a3f91",
   "metadata": {},
   "source": [
    "## Downloading mulitple 10 filings based on the user selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e9fbd-b6c8-4c6d-bbb7-d1accfa786f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Downloading multiple 10-K filings\n",
    "def download_multiple_10k_filings(df, user_agent_email):\n",
    "    \"\"\"\n",
    "    Show how many 10-Ks are available, let the user choose how many to download,\n",
    "    and return a DataFrame with filing metadata and text.\n",
    "    \"\"\"\n",
    "    tenk_df = df[df['Form Type'].str.upper() == '10-K'].reset_index(drop=True)\n",
    "    total = len(tenk_df)\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"No 10-K filings found in the dataset.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Found {total} 10-K filings in the dataset.\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            limit = int(input(f\"Enter the number of 10-K filings to download (1 to {total}): \"))\n",
    "            if 1 <= limit <= total:\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Please enter a number between 1 and {total}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid integer.\")\n",
    "\n",
    "    results = []\n",
    "    for idx, row in tenk_df.head(limit).iterrows():\n",
    "        url, html_text = extract_filing_html_directly(row, user_agent_email)\n",
    "        if html_text:\n",
    "            cleaned_text = clean_filing_html(html_text)\n",
    "            results.append({\n",
    "                \"Company Name\": row['Company Name'],\n",
    "                \"CIK\": row['CIK'],\n",
    "                \"Date Filed\": row['Date Filed'],\n",
    "                \"Filing URL\": url,\n",
    "                \"Filing Text\": html_text,\n",
    "                \"Cleaned Text\": cleaned_text\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7217570-8434-4e0b-8457-1baf7a8abb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/data/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c7602-3ecc-4e04-9853-9ae1e0ac5421",
   "metadata": {},
   "source": [
    "### Downloading and creating the dataframe of the final cleaned text of the filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f4d24-e046-4c79-8d01-ca749939d6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the full process\n",
    "filings_df = download_multiple_10k_filings(filtered, \"simransukhawani3@gmail.com\")\n",
    "\n",
    "# Preview results\n",
    "print(filings_df[[\"Company Name\", \"Filing URL\"]].head())\n",
    "print(\"\\n Sample Cleaned Filing Text:\\n\")\n",
    "print(filings_df[\"Cleaned Text\"][0][:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5707ae-6424-4eb7-b73c-52a8ff7c4b44",
   "metadata": {},
   "source": [
    "### Creating the csv for the future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d751f85-3cfe-44bb-817b-3203ceb4f94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving the DataFrame to a CSV file\n",
    "filings_df.to_csv(\"sp500_filings_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f424b",
   "metadata": {},
   "source": [
    "### Loading the filings dataframe that was saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a33b0a-f61a-4762-9083-375fa3b2478c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved DataFrame\n",
    "df_full = pd.read_csv(\"sp500_filings_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31224219-c2e2-497f-bc8a-26df6b080b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with selected columns\n",
    "df_section = df_full[[\"Company Name\",\"CIK\",\"Date Filed\",\"Filing Text\", \"Cleaned Text\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801918e-9f57-4310-8b59-422a866fdef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_section.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af256c05-530a-49f2-bad5-17ece16c49cc",
   "metadata": {},
   "source": [
    "# Section Wise Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec999da-662d-4c58-acdb-e3287f6dc2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_10k_sections(text):\n",
    "    \"\"\"\n",
    "    Robustly extracts Item 1, Item 7, and Item 7A sections from plain 10-K text.\n",
    "    Handles common formatting variations and malformed headers.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text) < 100:\n",
    "        return {\"Item 1\": \"\", \"Item 7\": \"\", \"Item 7A\": \"\"}\n",
    "\n",
    "    # Lowercase to normalize matching\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Expanded regex patterns to handle various formats and noise\n",
    "    patterns = {\n",
    "        \"Item 1\": r\"(item[\\s]*1[\\s\\.:\\-–—]*((business)?[^a-z0-9]{0,10}))\",\n",
    "        \"Item 7\": r\"(item[\\s]*7[^a-z0-9]{0,10}(management'?s)?[^a-z0-9]{0,10}(discussion)?)\",\n",
    "        \"Item 7A\": r\"(item[\\s]*7a[^a-z0-9]{0,10}(quantitative)?[^a-z0-9]{0,10}(market)?[^a-z0-9]{0,10}(risk)?)\"\n",
    "    }\n",
    "\n",
    "    # Match section headers with start positions\n",
    "    matches = []\n",
    "    for section, pattern in patterns.items():\n",
    "        match = re.search(pattern, text_lower)\n",
    "        if match:\n",
    "            matches.append((section, match.start()))\n",
    "\n",
    "    # Sort by appearance in the text\n",
    "    matches.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Extract sections between start and next match\n",
    "    sections = {}\n",
    "    for i in range(len(matches)):\n",
    "        name, start = matches[i]\n",
    "        end = matches[i+1][1] if i + 1 < len(matches) else len(text)\n",
    "        sections[name] = text[start:end].strip()\n",
    "\n",
    "    return {\n",
    "        \"Item 1\": sections.get(\"Item 1\", \"\"),\n",
    "        \"Item 7\": sections.get(\"Item 7\", \"\"),\n",
    "        \"Item 7A\": sections.get(\"Item 7A\", \"\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de771d2-a7ba-40ef-aedc-d84a794359f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the section level text to the dataframe\n",
    "sections_df = df_section[\"Cleaned Text\"].apply(extract_10k_sections).apply(pd.Series)\n",
    "\n",
    "# Add the extracted sections as new columns\n",
    "df_section[\"Item 1 Text\"] = sections_df[\"Item 1\"]\n",
    "df_section[\"Item 7 Text\"] = sections_df[\"Item 7\"]\n",
    "df_section[\"Item 7A Text\"] = sections_df[\"Item 7A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c0dd1-10cb-4239-830f-2fc8592b5156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop rows where any of the important columns are NULL\n",
    "df_section = df_section.dropna(subset=[\"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\", \"Cleaned Text\"])\n",
    "\n",
    "# Drop rows where any of the important columns are empty strings\n",
    "df_section = df_section[\n",
    "    (df_section[\"Item 1 Text\"].str.strip() != \"\") &\n",
    "    (df_section[\"Item 7 Text\"].str.strip() != \"\") &\n",
    "    (df_section[\"Item 7A Text\"].str.strip() != \"\") &\n",
    "    (df_section[\"Cleaned Text\"].str.strip() != \"\")\n",
    "]\n",
    "\n",
    "# Drop rows where 'Cleaned Text' has less than 500 characters (counting spaces)\n",
    "df_section = df_section[df_section[\"Cleaned Text\"].str.len() >= 500]\n",
    "\n",
    "# Reset index\n",
    "df_section = df_section.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset shape: {df_section.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22bb57-0e7e-4d75-ab76-a06eb3faecb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking the number of null values in the important columns\n",
    "print(df_section[[\"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\"]].isnull().sum())\n",
    "print(df_section[[\"Item 1 Text\", \"Item 7 Text\", \"Item 7A Text\"]].eq(\"\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28e9d7-fbf7-468b-8b80-8635713a7004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_section.describe()\n",
    "df_section.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e19144-8a4f-450b-bd6a-0d9572a137c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_section.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37174c08-73aa-407d-818a-03406103e6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading the Loughran-McDonald_MasterDictionary_1993-2024\n",
    "lm_df = pd.read_csv(\"Loughran-McDonald_MasterDictionary_1993-2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f38e01-6cc0-4fe7-b3bd-bdac37d3574d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter only positive and negative words\n",
    "positive_words = set(lm_df[lm_df[\"Positive\"] > 0][\"Word\"].str.lower())\n",
    "negative_words = set(lm_df[lm_df[\"Negative\"] > 0][\"Word\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e58166-9277-4dec-a6b0-2e53c41e29b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing the sentiment score for the Lexicon method\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def compute_lm_sentiment_percent(text):\n",
    "    \"\"\"\n",
    "    Returns a sentiment score as a percentage:\n",
    "    ((positive - negative) / total tokens) * 100\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "\n",
    "    total = len(tokens)\n",
    "    pos = sum(1 for word in tokens if word in positive_words)\n",
    "    neg = sum(1 for word in tokens if word in negative_words)\n",
    "\n",
    "    sentiment_score = (pos - neg) / total if total > 0 else 0.0\n",
    "    return sentiment_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762d02b-edd4-459c-b018-40a88a976588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the sentiment analysis using Lexicon Method\n",
    "df_section.loc[:, \"Item1_LM_Sentiment%\"] = df_section[\"Item 1 Text\"].apply(compute_lm_sentiment_percent)\n",
    "df_section.loc[:, \"Item7_LM_Sentiments%\"] = df_section[\"Item 7 Text\"].apply(compute_lm_sentiment_percent)\n",
    "df_section.loc[:, \"Item7A_LM_Sentiments%\"] = df_section[\"Item 7A Text\"].apply(compute_lm_sentiment_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88355e81-0d2b-4db6-bc72-3d99e3a3e003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_section[[\"Company Name\", \"CIK\",\"Date Filed\", \"Item1_LM_Sentiment%\",\"Item7_LM_Sentiments%\",\"Item7A_LM_Sentiments%\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ce21e-714d-46a5-afab-5c5f9a7f1b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "finbert = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"yiyanghkust/finbert-tone\",\n",
    "    tokenizer=\"yiyanghkust/finbert-tone\",\n",
    "    device=0,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0ec42-3edb-4125-8061-5f5fa9e152cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# FinBERT Sentiment Function \n",
    "def get_finbert_sentiment(text, batch_size=16):\n",
    "    \"\"\"\n",
    "    Breaks long text into ~3-sentence chunks, runs FinBERT on each chunk,\n",
    "    and returns a single net sentiment percentage (positive% - negative%).\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or len(text.strip()) < 10:\n",
    "        return 0.0\n",
    "\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    import numpy as np\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Using the chunck size of 3 sentences\n",
    "    chunks = [' '.join(sentences[i:i+3]) for i in range(0, len(sentences), 3)]\n",
    "\n",
    "    positive = 0\n",
    "    neutral = 0\n",
    "    negative = 0\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        # Skip truly empty batch\n",
    "        batch = [b for b in batch if len(b.strip()) > 0]\n",
    "        if not batch:\n",
    "            continue\n",
    "        try:\n",
    "            results = finbert(batch)\n",
    "            for r in results:\n",
    "                label = r[\"label\"].lower()\n",
    "                if \"positive\" in label:\n",
    "                    positive += 1\n",
    "                elif \"neutral\" in label:\n",
    "                    neutral += 1\n",
    "                elif \"negative\" in label:\n",
    "                    negative += 1\n",
    "        except Exception as e:\n",
    "            print(\"Error during FinBERT batch:\", e)\n",
    "            continue\n",
    "\n",
    "    total = positive + neutral + negative\n",
    "\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    positive_pct = (positive / total) * 100\n",
    "    negative_pct = (negative / total) * 100\n",
    "\n",
    "    return positive_pct - negative_pct  # Only return net sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50297806-1ccb-49ee-a735-cb8444b27690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting Dataframe into Dataset for better usage for the section level sentiment analysis\n",
    "df_finbert = Dataset.from_pandas(df_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8c840-0afa-4471-9326-c924f8c048a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function for batch\n",
    "def get_batch_sentiment(text_list):\n",
    "    \"\"\"Efficiently get FinBERT sentiment for a list of texts.\"\"\"\n",
    "    scores = []\n",
    "    if not text_list:\n",
    "        return [0.0] * len(text_list)\n",
    "\n",
    "    for text in text_list:\n",
    "        scores.append(get_finbert_sentiment(text))\n",
    "    return scores\n",
    "\n",
    "def apply_finbert_sentiment_batch(batch):\n",
    "    item1_sentiments = get_batch_sentiment(batch['Item 1 Text'])\n",
    "    item7_sentiments = get_batch_sentiment(batch['Item 7 Text'])\n",
    "    item7a_sentiments = get_batch_sentiment(batch['Item 7A Text'])\n",
    "    \n",
    "    return {\n",
    "        \"Item 1 FinBERT Sentiment\": item1_sentiments,\n",
    "        \"Item 7 FinBERT Sentiment\": item7_sentiments,\n",
    "        \"Item 7A FinBERT Sentiment\": item7a_sentiments\n",
    "    }\n",
    "\n",
    "# Filtering based on text length\n",
    "df_finbert = df_finbert.filter(lambda example: len(example[\"Cleaned Text\"]) >= 500)\n",
    "print(f\"Dataset after length filtering: {len(df_finbert)} rows\")\n",
    "\n",
    "# Now run the optimized batch map\n",
    "df_finbert = df_finbert.map(\n",
    "    apply_finbert_sentiment_batch,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    num_proc=1,\n",
    "    desc=\"Applying Section-wise FinBERT Net Sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e8621-b32a-4488-ba17-00715b5b12ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convering the Dataset back to DataFrame\n",
    "df_sentiment = df_finbert.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e64541-529c-4bdc-aa6a-417f1f6b4fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sentiment[[\"Company Name\", \"CIK\",\"Date Filed\",\"Item 1 FinBERT Sentiment\",\"Item 7 FinBERT Sentiment\",\"Item 7A FinBERT Sentiment\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e9aaa-b10d-4693-bc1d-4fe6c5d22190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only needed columns\n",
    "selected_columns = df_sentiment[[\n",
    "    \"Company Name\", \n",
    "    \"CIK\", \n",
    "    \"Date Filed\", \n",
    "    \"Item 1 FinBERT Sentiment\", \n",
    "    \"Item 7 FinBERT Sentiment\", \n",
    "    \"Item 7A FinBERT Sentiment\"\n",
    "]]\n",
    "\n",
    "# Save to CSV\n",
    "df_sentiment.to_csv(\"sentiment_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf2cb2-ce09-4de6-9acc-82584504f1ff",
   "metadata": {},
   "source": [
    "# Applying Document level sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430126b8-2523-43df-b597-efdf08456a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering only the Cleaned Text with length greater than 500\n",
    "df_full_filtered = df_full[df_full[\"Cleaned Text\"].str.len() >= 500].copy()\n",
    "\n",
    "print(f\"Dataset after full document length filtering: {len(df_full_filtered)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00509cee-2a76-422f-a49e-1e30ee88c3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe66a91-16a6-4bd8-95bd-912180f16216",
   "metadata": {},
   "source": [
    "### Applying Lexicon method at full document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa17f7-7406-4f68-a90c-fececbaa5967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying the Loughran-McDonald sentiment analysis on the full Document text\n",
    "df_full_filtered[\"LM_Sentiment%\"] = df_full_filtered[\"Cleaned Text\"].progress_apply(compute_lm_sentiment_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238b23d-8f6f-4579-86ee-c51230498a94",
   "metadata": {},
   "source": [
    "### Applying FinBERT at full document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1407e90-6efd-4940-90b1-b6aa5499e49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the dataframe to a Dataset\n",
    "hf_full = Dataset.from_pandas(df_full_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9876d0-fe20-400a-9cc6-b843c83dc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the mapping function\n",
    "def apply_finbert_full_document(batch):\n",
    "    sentiments = get_batch_sentiment(batch[\"Cleaned Text\"])\n",
    "    return {\n",
    "        \"Full Document FinBERT Sentiment\": sentiments\n",
    "    }\n",
    "\n",
    "# Run map() on the HuggingFace Dataset\n",
    "hf_full = hf_full.map(\n",
    "    apply_finbert_full_document,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    num_proc=1,\n",
    "    desc=\"Applying FinBERT Sentiment at Full Document Level\"\n",
    ")\n",
    "\n",
    "# Step 3: Done! View the new columns\n",
    "print(hf_full.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095cd8f-8172-42ce-b545-95bc99b18211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas\n",
    "df_full_sentiment = hf_full.to_pandas()\n",
    "\n",
    "# Save to CSV\n",
    "df_full_sentiment.to_csv(\"full_document_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c102d-fdc3-49c1-9445-bdba97940fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ce082-6418-4c4e-8201-a6e7a33d056d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only necessary columns cleanly\n",
    "section_lm = df_section[[\n",
    "    \"Company Name\", \"CIK\", \"Date Filed\",\n",
    "    \"Item1_LM_Sentiment%\",\n",
    "    \"Item7_LM_Sentiments%\",\n",
    "    \"Item7A_LM_Sentiments%\"\n",
    "]]\n",
    "\n",
    "section_finbert = df_sentiment[[\n",
    "    \"Company Name\", \"CIK\", \"Date Filed\",\n",
    "    \"Item 1 FinBERT Sentiment\",\n",
    "    \"Item 7 FinBERT Sentiment\",\n",
    "    \"Item 7A FinBERT Sentiment\"\n",
    "]]\n",
    "\n",
    "full_document_sentiment = df_full_sentiment[[\n",
    "    \"Company Name\", \"CIK\", \"Date Filed\",\n",
    "    \"LM_Sentiment%\",   # Full-document LM\n",
    "    \"Full Document FinBERT Sentiment\"\n",
    "]]\n",
    "\n",
    "# Merge Section-level FinBERT and Section-level LM\n",
    "merged_sections = pd.merge(section_finbert, section_lm, on=[\"Company Name\", \"CIK\", \"Date Filed\"], how=\"inner\")\n",
    "\n",
    "# Merge with Full-document level sentiments\n",
    "master_sentiment = pd.merge(merged_sections, full_document_sentiment, on=[\"Company Name\", \"CIK\", \"Date Filed\"], how=\"inner\")\n",
    "\n",
    "# Check the final merged master table\n",
    "print(master_sentiment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65831860-eb7c-42fd-bf2c-fd947ad6da64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "master_sentiment.to_csv(\"master_sentiment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683753a-274d-43f6-86da-88f4d3797126",
   "metadata": {},
   "source": [
    "## Pearson Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde878bc-331a-46e1-a16c-8158a9ca4632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Columns mapping: FinBERT field -> LM field\n",
    "field_mapping = {\n",
    "    \"Item 1 FinBERT Sentiment\": \"Item1_LM_Sentiment%\",\n",
    "    \"Item 7 FinBERT Sentiment\": \"Item7_LM_Sentiments%\",\n",
    "    \"Item 7A FinBERT Sentiment\": \"Item7A_LM_Sentiments%\",\n",
    "    \"Full Document FinBERT Sentiment\": \"LM_Sentiment%\"\n",
    "}\n",
    "\n",
    "# Prepare a place to store results\n",
    "comparison_results = []\n",
    "\n",
    "# Loop over each field pair\n",
    "for finbert_col, lm_col in field_mapping.items():\n",
    "    \n",
    "    print(f\"\\n Comparing {finbert_col} vs {lm_col}\")\n",
    "    \n",
    "    # Drop any rows with missing values (important)\n",
    "    temp_df = master_sentiment[[finbert_col, lm_col]].dropna()\n",
    "    \n",
    "    # Pearson Correlation\n",
    "    r, p_corr = pearsonr(temp_df[finbert_col], temp_df[lm_col])\n",
    "    \n",
    "    # Paired t-test\n",
    "    t_stat, p_ttest = ttest_rel(temp_df[finbert_col], temp_df[lm_col])\n",
    "    \n",
    "    # Mean and Standard Deviation\n",
    "    finbert_mean = temp_df[finbert_col].mean()\n",
    "    finbert_std = temp_df[finbert_col].std()\n",
    "    \n",
    "    lm_mean = temp_df[lm_col].mean()\n",
    "    lm_std = temp_df[lm_col].std()\n",
    "    \n",
    "    # Collect results\n",
    "    comparison_results.append({\n",
    "        \"Field\": finbert_col.split()[1],  # \"Item 1\", \"Item 7\" etc\n",
    "        \"Pearson r\": r,\n",
    "        \"p-value (corr)\": p_corr,\n",
    "        \"t-statistic\": t_stat,\n",
    "        \"p-value (t-test)\": p_ttest,\n",
    "        \"FinBERT Mean\": finbert_mean,\n",
    "        \"FinBERT Std\": finbert_std,\n",
    "        \"LM Mean\": lm_mean,\n",
    "        \"LM Std\": lm_std\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Print final result table\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x) \n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027af12-e723-4a92-a022-d73607d6f387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0746d-09dd-4b37-b58d-a889cf912420",
   "metadata": {},
   "source": [
    "## Classify Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ca04d-fafb-47df-a87f-b1df146c2f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sentiment classification function\n",
    "def classify_sentiment(score):\n",
    "    if score > 2.0:\n",
    "        return \"Positive\"\n",
    "    elif score < -2.0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply classification for each method and section\n",
    "# Full Document\n",
    "master_sentiment[\"Full Doc FinBERT Class\"] = master_sentiment[\"Full Document FinBERT Sentiment\"].apply(classify_sentiment)\n",
    "master_sentiment[\"Full Doc LM Class\"] = master_sentiment[\"LM_Sentiment%\"].apply(classify_sentiment)\n",
    "\n",
    "# Section Level\n",
    "master_sentiment[\"Item 1 FinBERT Class\"] = master_sentiment[\"Item 1 FinBERT Sentiment\"].apply(classify_sentiment)\n",
    "master_sentiment[\"Item 1 LM Class\"] = master_sentiment[\"Item1_LM_Sentiment%\"].apply(classify_sentiment)\n",
    "\n",
    "master_sentiment[\"Item 7 FinBERT Class\"] = master_sentiment[\"Item 7 FinBERT Sentiment\"].apply(classify_sentiment)\n",
    "master_sentiment[\"Item 7 LM Class\"] = master_sentiment[\"Item7_LM_Sentiments%\"].apply(classify_sentiment)\n",
    "\n",
    "master_sentiment[\"Item 7A FinBERT Class\"] = master_sentiment[\"Item 7A FinBERT Sentiment\"].apply(classify_sentiment)\n",
    "master_sentiment[\"Item 7A LM Class\"] = master_sentiment[\"Item7A_LM_Sentiments%\"].apply(classify_sentiment)\n",
    "\n",
    "print(master_sentiment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be27023-5d7e-4bbd-95e0-3b06de7326db",
   "metadata": {},
   "source": [
    "## Agreement Analysis\n",
    "* Compare if LM and FinBERT classified the same for each filing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d44c70-1c6b-42fb-9a7a-e79a7821ba3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Document Agreement\n",
    "master_sentiment[\"Full Doc Agreement\"] = (\n",
    "    master_sentiment[\"Full Doc FinBERT Class\"] == master_sentiment[\"Full Doc LM Class\"]\n",
    ")\n",
    "\n",
    "# Section Agreement\n",
    "master_sentiment[\"Item 1 Agreement\"] = (\n",
    "    master_sentiment[\"Item 1 FinBERT Class\"] == master_sentiment[\"Item 1 LM Class\"]\n",
    ")\n",
    "\n",
    "master_sentiment[\"Item 7 Agreement\"] = (\n",
    "    master_sentiment[\"Item 7 FinBERT Class\"] == master_sentiment[\"Item 7 LM Class\"]\n",
    ")\n",
    "\n",
    "master_sentiment[\"Item 7A Agreement\"] = (\n",
    "    master_sentiment[\"Item 7A FinBERT Class\"] == master_sentiment[\"Item 7A LM Class\"]\n",
    ")\n",
    "\n",
    "# Calculate agreement percentages\n",
    "print(\"\\nAgreement Rates (%):\")\n",
    "print(\"Full Document:\", master_sentiment[\"Full Doc Agreement\"].mean() * 100)\n",
    "print(\"Item 1:\", master_sentiment[\"Item 1 Agreement\"].mean() * 100)\n",
    "print(\"Item 7:\", master_sentiment[\"Item 7 Agreement\"].mean() * 100)\n",
    "print(\"Item 7A:\", master_sentiment[\"Item 7A Agreement\"].mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c20a3-d939-4589-b013-8ee1b8904ee4",
   "metadata": {},
   "source": [
    "## Agreement Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5a458-e610-47d8-bec1-84628b70afa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare Agreement Rates\n",
    "agreement_rates = {\n",
    "    \"Full Document\": master_sentiment[\"Full Doc Agreement\"].mean() * 100,\n",
    "    \"Item 1\": master_sentiment[\"Item 1 Agreement\"].mean() * 100,\n",
    "    \"Item 7\": master_sentiment[\"Item 7 Agreement\"].mean() * 100,\n",
    "    \"Item 7A\": master_sentiment[\"Item 7A Agreement\"].mean() * 100\n",
    "}\n",
    "\n",
    "# Bar Chart Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(agreement_rates.keys(), agreement_rates.values(), color=\"skyblue\")\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f'{yval:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel(\"Agreement Rate (%)\")\n",
    "plt.title(\"Agreement Rates Between LM and FinBERT Sentiment Classification\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"agreement_bar_chart.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb103b-ed59-4b06-98ea-11b033f4ae9e",
   "metadata": {},
   "source": [
    "## Confusion Matrix (LM vs FinBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0052da66-6ee4-4fed-ba19-23a5ab87baeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(\n",
    "    master_sentiment[\"Full Doc LM Class\"], \n",
    "    master_sentiment[\"Full Doc FinBERT Class\"],\n",
    "    labels=[\"Positive\", \"Neutral\", \"Negative\"]  # consistent label ordering\n",
    ")\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=[\"Positive\", \"Neutral\", \"Negative\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "disp.plot(cmap=\"Blues\", values_format='d', ax=ax)\n",
    "plt.title(\"Confusion Matrix: LM vs FinBERT (Full Document)\")\n",
    "plt.savefig(\"confusion_matrix_full_doc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5395e4-1741-4a57-bdf1-1d92a4798d82",
   "metadata": {},
   "source": [
    "## Class Distribution Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015e35f-2ad5-4c74-ad90-e3a126c0dafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define all sections\n",
    "sections = {\n",
    "    \"Full Document\": (\"Full Doc FinBERT Class\", \"Full Doc LM Class\"),\n",
    "    \"Item 1\": (\"Item 1 FinBERT Class\", \"Item 1 LM Class\"),\n",
    "    \"Item 7\": (\"Item 7 FinBERT Class\", \"Item 7 LM Class\"),\n",
    "    \"Item 7A\": (\"Item 7A FinBERT Class\", \"Item 7A LM Class\")\n",
    "}\n",
    "\n",
    "# Prepare the figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))  # 2 rows, 2 columns\n",
    "axes = axes.flatten()  # flatten axes for easy looping\n",
    "\n",
    "# Plot each section\n",
    "for idx, (section_name, (finbert_col, lm_col)) in enumerate(sections.items()):\n",
    "    # Count class distributions\n",
    "    finbert_counts = master_sentiment[finbert_col].value_counts()\n",
    "    lm_counts = master_sentiment[lm_col].value_counts()\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    class_distribution = pd.DataFrame({\n",
    "        \"FinBERT\": finbert_counts,\n",
    "        \"LM\": lm_counts\n",
    "    }).reindex([\"Positive\", \"Neutral\", \"Negative\"])\n",
    "    \n",
    "    # Plot on corresponding axis\n",
    "    class_distribution.plot(kind=\"bar\", ax=axes[idx], color=[\"skyblue\", \"salmon\"], legend=False)\n",
    "    axes[idx].set_title(section_name)\n",
    "    axes[idx].set_ylabel(\"Number of Documents\")\n",
    "    axes[idx].set_xlabel(\"\")\n",
    "    axes[idx].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[idx].set_xticklabels([\"Positive\", \"Neutral\", \"Negative\"], rotation=0)\n",
    "\n",
    "# Add one shared legend\n",
    "fig.legend([\"FinBERT\", \"LM\"], loc=\"upper center\", ncol=2, fontsize=\"large\")\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # leave space for legend\n",
    "plt.suptitle(\"Class Distribution Comparison: FinBERT vs LM\", fontsize=16)\n",
    "plt.savefig(\"class_distribution_all_sections.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e53c8-bf31-41a2-970c-9dc72817c5db",
   "metadata": {},
   "source": [
    "## Comparing All 3 different level sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110415a-d2a1-4d49-b2ee-f8dfb6f67973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define all sections and corresponding columns\n",
    "sections = {\n",
    "    \"Full Document\": (\"LM_Sentiment%\", \"Full Document FinBERT Sentiment\"),\n",
    "    \"Item 1\": (\"Item1_LM_Sentiment%\", \"Item 1 FinBERT Sentiment\"),\n",
    "    \"Item 7\": (\"Item7_LM_Sentiments%\", \"Item 7 FinBERT Sentiment\"),\n",
    "    \"Item 7A\": (\"Item7A_LM_Sentiments%\", \"Item 7A FinBERT Sentiment\")\n",
    "}\n",
    "\n",
    "# Prepare a subplot grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()  # flatten axes to access easily\n",
    "\n",
    "# Loop through each section and plot\n",
    "for idx, (section_name, (lm_col, finbert_col)) in enumerate(sections.items()):\n",
    "    \n",
    "    # Scatter plot\n",
    "    sns.scatterplot(\n",
    "        x=master_sentiment[lm_col],\n",
    "        y=master_sentiment[finbert_col],\n",
    "        color=\"blue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "        ax=axes[idx]\n",
    "    )\n",
    "    \n",
    "    # Perfect agreement line (y = x)\n",
    "    lims = [\n",
    "        min(master_sentiment[lm_col].min(), master_sentiment[finbert_col].min()),\n",
    "        max(master_sentiment[lm_col].max(), master_sentiment[finbert_col].max())\n",
    "    ]\n",
    "    axes[idx].plot(lims, lims, 'k--', alpha=0.75)\n",
    "\n",
    "    # Regression trend line\n",
    "    sns.regplot(\n",
    "        x=master_sentiment[lm_col],\n",
    "        y=master_sentiment[finbert_col],\n",
    "        scatter=False,\n",
    "        color=\"red\",\n",
    "        line_kws={\"linewidth\":1.5, \"linestyle\":\"-.\"},\n",
    "        ax=axes[idx]\n",
    "    )\n",
    "    \n",
    "    # Labels and titles\n",
    "    axes[idx].set_xlabel(f\"{section_name} LM Sentiment (%)\")\n",
    "    axes[idx].set_ylabel(f\"{section_name} FinBERT Sentiment (%)\")\n",
    "    axes[idx].set_title(section_name)\n",
    "    axes[idx].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Layout adjustment\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Correlation Scatter Plots: LM vs FinBERT (Full Document and Section Level)\", fontsize=18, y=1.03)\n",
    "plt.savefig(\"correlation_scatter_full_and_sections.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project10k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
